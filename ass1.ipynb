{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzi27/adv-ml-assignment1/blob/master/ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABVe6x05udwR",
        "colab_type": "text"
      },
      "source": [
        "# Amrani Hamza - 807386\n",
        "\n",
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsPy5ahXujZt",
        "colab_type": "code",
        "outputId": "80106075-09ef-4b34-aa20-d7493e3ca931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url_train = 'https://raw.githubusercontent.com/hamzi27/adv-ml-assignment1/master/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/hamzi27/adv-ml-assignment1/master/test.csv'\n",
        "\n",
        "train = pd.read_csv(url_train)\n",
        "test = pd.read_csv(url_test)\n",
        "\n",
        "print(train.head())\n",
        "print(\"Training set data shape: \", train.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   LIMIT_BAL  SEX  EDUCATION  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n",
            "0    20000.0    2          2  ...       0.0       0.0                           1\n",
            "1   120000.0    2          2  ...       0.0    2000.0                           1\n",
            "2    90000.0    2          2  ...    1000.0    5000.0                           0\n",
            "3    50000.0    2          2  ...    1069.0    1000.0                           0\n",
            "4    50000.0    1          2  ...     689.0     679.0                           0\n",
            "\n",
            "[5 rows x 24 columns]\n",
            "Training set data shape:  (27000, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0a7BVVIpvzO",
        "colab_type": "text"
      },
      "source": [
        "# Analysis on data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlQ4_442smWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U pandas_profiling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62TFvroXpyiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas_profiling\n",
        "\n",
        "# train.profile_report(style={'full_width':True})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb7jLOZtuVMH",
        "colab_type": "text"
      },
      "source": [
        "# Removing columns highly correlated and duplicates rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL_qakFeuc7N",
        "colab_type": "code",
        "outputId": "48909549-640b-4f14-dfd0-5db7a430fddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Drop of duplicates rows\n",
        "train = train.drop_duplicates()\n",
        "test = test.drop_duplicates()\n",
        "\n",
        "# Drop columns lowly correlated to target\n",
        "\n",
        "train.drop(columns=['AGE','EDUCATION','LIMIT_BAL','MARRIAGE','SEX','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6'], axis=1, inplace=True)\n",
        "test.drop(columns=['AGE','EDUCATION','LIMIT_BAL','MARRIAGE','SEX','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6'], axis=1, inplace=True)\n",
        "\n",
        "print(\"Train shape: \", train.shape)\n",
        "print(\"Number of 0: \", sum(train['default.payment.next.month']==0))\n",
        "print(\"Number of 1: \", sum(train['default.payment.next.month']==1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape:  (26973, 13)\n",
            "Number of 0:  21004\n",
            "Number of 1:  5969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9YrxFoahyvI",
        "colab_type": "text"
      },
      "source": [
        "# Split train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNQk-sc-h1-A",
        "colab_type": "code",
        "outputId": "72c380f5-d1c6-497a-dbec-e2db53e6e2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, validation = train_test_split( train,test_size=0.2)\n",
        "\n",
        "print(\"Train: \", train.shape)\n",
        "\n",
        "num_0 = sum(train['default.payment.next.month']==0)\n",
        "num_1 = sum(train['default.payment.next.month']==1)\n",
        "print(\"Number of 0: \", num_0)\n",
        "print(\"Number of 1: \", num_1)\n",
        "\n",
        "print(\"\\nValidation: \", validation.shape)\n",
        "print(\"Number of 0: \", sum(validation['default.payment.next.month']==0))\n",
        "print(\"Number of 1: \", sum(validation['default.payment.next.month']==1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (21578, 13)\n",
            "Number of 0:  16757\n",
            "Number of 1:  4821\n",
            "\n",
            "Validation:  (5395, 13)\n",
            "Number of 0:  4247\n",
            "Number of 1:  1148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HktIjzJ01HNV",
        "colab_type": "text"
      },
      "source": [
        "# Over-sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ISu_VF31NH",
        "colab_type": "code",
        "outputId": "7594f7b4-5a7f-4768-871a-7f2dca9f26a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from numpy.random import random_sample\n",
        "\n",
        "train_1 = train[train['default.payment.next.month']==1]\n",
        "\n",
        "values = [train_1[column].value_counts(normalize=True).keys().tolist() for column in train_1.columns[:-1]]\n",
        "probabilities = [train_1[column].value_counts(normalize=True).tolist() for column in train_1.columns[:-1]]\n",
        "\n",
        "verify = {}\n",
        "for index, row in train_1.iterrows():\n",
        "    verify [str(row.values)]=1\n",
        "    \n",
        "sample_rows = []\n",
        "for _ in range(num_0-num_1):\n",
        "  while True:\n",
        "    sample_row = []\n",
        "    \n",
        "    for i in range(len(values)):\n",
        "      bins = np.add.accumulate(probabilities[i])\n",
        "      sample_of_column = [values[i][n] for n in np.digitize(random_sample(1), bins)]\n",
        "      sample_row.extend(sample_of_column)\n",
        "    sample_row.extend([1])\n",
        "    \n",
        "    try:\n",
        "      verify[str(sample_row)]\n",
        "    except:\n",
        "      verify[str(sample_row)] = 1\n",
        "      break\n",
        "  \n",
        "  sample_rows.append(sample_row)\n",
        "\n",
        "train_oversample = pd.DataFrame(sample_rows, columns = train.columns) \n",
        "train = train.append(train_oversample, ignore_index=True)\n",
        "\n",
        "print(train.head())\n",
        "\n",
        "print(\"Ended over-sample on train!\")\n",
        "print(\"Number of 0: \", sum(train['default.payment.next.month']==0))\n",
        "print(\"Number of 1: \", sum(train['default.payment.next.month']==1))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PAY_0  PAY_2  PAY_3  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n",
            "0      0      0      0  ...    1600.0    2600.0                           0\n",
            "1      0      0      0  ...    4300.0    5012.0                           0\n",
            "2      0      0      0  ...   12508.0   19216.0                           0\n",
            "3      2      0      0  ...    1568.0    7400.0                           1\n",
            "4      2      0     -1  ...    2030.0       0.0                           1\n",
            "\n",
            "[5 rows x 13 columns]\n",
            "Ended over-sample on train!\n",
            "Number of 0:  16757\n",
            "Number of 1:  16757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRgLhpASlgK",
        "colab_type": "text"
      },
      "source": [
        "# Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB7BcrYNSpgw",
        "colab_type": "code",
        "outputId": "706b15ec-8d54-4d4c-9957-10188ff11f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def load_data(df, train=True):\n",
        "    X = df.values.copy()\n",
        "    if train:\n",
        "        np.random.shuffle(X)  \n",
        "        X, labels = X[:, 0:-1].astype(np.float32), X[:, -1]\n",
        "        return X, labels\n",
        "    else:\n",
        "        X, ids = X[:, 0:].astype(np.float32), X[:, 0].astype(str)\n",
        "        return X, ids\n",
        "\n",
        "\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    \"\"\"Encode labels with values among 0 and `n-classes-1`\"\"\"\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = np_utils.to_categorical(y)\n",
        "    return y, encoder\n",
        "  \n",
        "\n",
        "X_train, Y_train = load_data(train, train=True)\n",
        "X_val, Y_val = load_data(validation, train=True)\n",
        "X_test, Y_test = load_data(test, train=False)\n",
        "  \n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "Y_train, encoder = preprocess_labels(Y_train)\n",
        "Y_val, encoder_val = preprocess_labels(Y_val)\n",
        "\n",
        "nb_classes = Y_train.shape[1]\n",
        "dims = X_train.shape[1]\n",
        "\n",
        "print(nb_classes, 'classes')\n",
        "print(dims, 'dims')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 classes\n",
            "12 dims\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOsKfsy4Ta5C",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTA4XjQwBF96",
        "colab_type": "code",
        "outputId": "60131774-9f45-47a0-f442-e69b37c3824b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install keras_metrics"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.16.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3OAAJsOTeyH",
        "colab_type": "code",
        "outputId": "7c50a152-3d6f-4707-944c-f1decbc54886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers.core import Activation, Dropout\n",
        "import keras_metrics\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(dims,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics =[\"accuracy\", keras_metrics.binary_precision(), keras_metrics.binary_recall(), keras_metrics.binary_f1_score()])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 64)                832       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 2,978\n",
            "Trainable params: 2,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umdZhxDfC4mX",
        "colab_type": "code",
        "outputId": "882c2d70-cb44-4f0e-ab8d-63aeb8818731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=64, verbose=True) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 26811 samples, validate on 6703 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Epoch 1/100\n",
            "26811/26811 [==============================] - 1s 30us/step - loss: 0.5614 - acc: 0.7689 - precision: 0.7750 - recall: 0.7577 - f1_score: 0.7662 - val_loss: 0.5121 - val_acc: 0.8046 - val_precision: 0.7994 - val_recall: 0.8137 - val_f1_score: 0.8064\n",
            "Epoch 2/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4905 - acc: 0.8006 - precision: 0.8013 - recall: 0.7993 - f1_score: 0.8003 - val_loss: 0.4694 - val_acc: 0.8099 - val_precision: 0.8134 - val_recall: 0.8047 - val_f1_score: 0.8091\n",
            "Epoch 3/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.4598 - acc: 0.8057 - precision: 0.8107 - recall: 0.7975 - f1_score: 0.8040 - val_loss: 0.4455 - val_acc: 0.8144 - val_precision: 0.8183 - val_recall: 0.8086 - val_f1_score: 0.8134\n",
            "Epoch 4/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.4425 - acc: 0.8083 - precision: 0.8137 - recall: 0.7995 - f1_score: 0.8065 - val_loss: 0.4305 - val_acc: 0.8190 - val_precision: 0.8187 - val_recall: 0.8199 - val_f1_score: 0.8193\n",
            "Epoch 5/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.4320 - acc: 0.8129 - precision: 0.8130 - recall: 0.8127 - f1_score: 0.8128 - val_loss: 0.4214 - val_acc: 0.8240 - val_precision: 0.8253 - val_recall: 0.8223 - val_f1_score: 0.8238\n",
            "Epoch 6/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.4254 - acc: 0.8158 - precision: 0.8143 - recall: 0.8180 - f1_score: 0.8162 - val_loss: 0.4157 - val_acc: 0.8249 - val_precision: 0.8210 - val_recall: 0.8312 - val_f1_score: 0.8261\n",
            "Epoch 7/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4210 - acc: 0.8174 - precision: 0.8140 - recall: 0.8227 - f1_score: 0.8183 - val_loss: 0.4107 - val_acc: 0.8271 - val_precision: 0.8262 - val_recall: 0.8289 - val_f1_score: 0.8275\n",
            "Epoch 8/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4176 - acc: 0.8190 - precision: 0.8161 - recall: 0.8234 - f1_score: 0.8197 - val_loss: 0.4069 - val_acc: 0.8287 - val_precision: 0.8265 - val_recall: 0.8324 - val_f1_score: 0.8295\n",
            "Epoch 9/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4147 - acc: 0.8202 - precision: 0.8173 - recall: 0.8248 - f1_score: 0.8210 - val_loss: 0.4045 - val_acc: 0.8290 - val_precision: 0.8257 - val_recall: 0.8345 - val_f1_score: 0.8301\n",
            "Epoch 10/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4123 - acc: 0.8225 - precision: 0.8198 - recall: 0.8265 - f1_score: 0.8232 - val_loss: 0.4022 - val_acc: 0.8283 - val_precision: 0.8199 - val_recall: 0.8417 - val_f1_score: 0.8307\n",
            "Epoch 11/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4104 - acc: 0.8231 - precision: 0.8196 - recall: 0.8286 - f1_score: 0.8241 - val_loss: 0.3995 - val_acc: 0.8286 - val_precision: 0.8230 - val_recall: 0.8375 - val_f1_score: 0.8302\n",
            "Epoch 12/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4086 - acc: 0.8235 - precision: 0.8200 - recall: 0.8291 - f1_score: 0.8245 - val_loss: 0.3977 - val_acc: 0.8301 - val_precision: 0.8230 - val_recall: 0.8414 - val_f1_score: 0.8321\n",
            "Epoch 13/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4067 - acc: 0.8247 - precision: 0.8206 - recall: 0.8309 - f1_score: 0.8258 - val_loss: 0.3956 - val_acc: 0.8320 - val_precision: 0.8275 - val_recall: 0.8393 - val_f1_score: 0.8333\n",
            "Epoch 14/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4051 - acc: 0.8260 - precision: 0.8217 - recall: 0.8326 - f1_score: 0.8271 - val_loss: 0.3944 - val_acc: 0.8313 - val_precision: 0.8226 - val_recall: 0.8450 - val_f1_score: 0.8337\n",
            "Epoch 15/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.4036 - acc: 0.8267 - precision: 0.8208 - recall: 0.8357 - f1_score: 0.8282 - val_loss: 0.3929 - val_acc: 0.8331 - val_precision: 0.8270 - val_recall: 0.8426 - val_f1_score: 0.8347\n",
            "Epoch 16/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.4022 - acc: 0.8260 - precision: 0.8220 - recall: 0.8321 - f1_score: 0.8270 - val_loss: 0.3927 - val_acc: 0.8332 - val_precision: 0.8174 - val_recall: 0.8584 - val_f1_score: 0.8374\n",
            "Epoch 17/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.4010 - acc: 0.8281 - precision: 0.8219 - recall: 0.8377 - f1_score: 0.8297 - val_loss: 0.3904 - val_acc: 0.8341 - val_precision: 0.8194 - val_recall: 0.8575 - val_f1_score: 0.8380\n",
            "Epoch 18/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3994 - acc: 0.8290 - precision: 0.8209 - recall: 0.8415 - f1_score: 0.8311 - val_loss: 0.3894 - val_acc: 0.8350 - val_precision: 0.8269 - val_recall: 0.8476 - val_f1_score: 0.8372\n",
            "Epoch 19/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3982 - acc: 0.8303 - precision: 0.8223 - recall: 0.8425 - f1_score: 0.8323 - val_loss: 0.3883 - val_acc: 0.8372 - val_precision: 0.8385 - val_recall: 0.8357 - val_f1_score: 0.8371\n",
            "Epoch 20/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3973 - acc: 0.8313 - precision: 0.8224 - recall: 0.8450 - f1_score: 0.8335 - val_loss: 0.3863 - val_acc: 0.8368 - val_precision: 0.8268 - val_recall: 0.8524 - val_f1_score: 0.8394\n",
            "Epoch 21/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3959 - acc: 0.8333 - precision: 0.8239 - recall: 0.8477 - f1_score: 0.8356 - val_loss: 0.3857 - val_acc: 0.8372 - val_precision: 0.8247 - val_recall: 0.8569 - val_f1_score: 0.8405\n",
            "Epoch 22/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3948 - acc: 0.8333 - precision: 0.8227 - recall: 0.8497 - f1_score: 0.8359 - val_loss: 0.3846 - val_acc: 0.8398 - val_precision: 0.8233 - val_recall: 0.8655 - val_f1_score: 0.8439\n",
            "Epoch 23/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3937 - acc: 0.8342 - precision: 0.8219 - recall: 0.8532 - f1_score: 0.8373 - val_loss: 0.3843 - val_acc: 0.8408 - val_precision: 0.8337 - val_recall: 0.8518 - val_f1_score: 0.8426\n",
            "Epoch 24/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3925 - acc: 0.8357 - precision: 0.8241 - recall: 0.8535 - f1_score: 0.8386 - val_loss: 0.3839 - val_acc: 0.8411 - val_precision: 0.8189 - val_recall: 0.8763 - val_f1_score: 0.8466\n",
            "Epoch 25/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3917 - acc: 0.8361 - precision: 0.8217 - recall: 0.8584 - f1_score: 0.8397 - val_loss: 0.3817 - val_acc: 0.8410 - val_precision: 0.8221 - val_recall: 0.8706 - val_f1_score: 0.8456\n",
            "Epoch 26/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3905 - acc: 0.8382 - precision: 0.8229 - recall: 0.8619 - f1_score: 0.8419 - val_loss: 0.3809 - val_acc: 0.8422 - val_precision: 0.8260 - val_recall: 0.8673 - val_f1_score: 0.8461\n",
            "Epoch 27/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3897 - acc: 0.8373 - precision: 0.8226 - recall: 0.8600 - f1_score: 0.8409 - val_loss: 0.3803 - val_acc: 0.8432 - val_precision: 0.8219 - val_recall: 0.8766 - val_f1_score: 0.8484\n",
            "Epoch 28/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3891 - acc: 0.8383 - precision: 0.8217 - recall: 0.8641 - f1_score: 0.8424 - val_loss: 0.3791 - val_acc: 0.8454 - val_precision: 0.8278 - val_recall: 0.8727 - val_f1_score: 0.8496\n",
            "Epoch 29/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3882 - acc: 0.8388 - precision: 0.8226 - recall: 0.8638 - f1_score: 0.8427 - val_loss: 0.3789 - val_acc: 0.8434 - val_precision: 0.8223 - val_recall: 0.8763 - val_f1_score: 0.8484\n",
            "Epoch 30/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3873 - acc: 0.8402 - precision: 0.8221 - recall: 0.8682 - f1_score: 0.8445 - val_loss: 0.3780 - val_acc: 0.8453 - val_precision: 0.8305 - val_recall: 0.8679 - val_f1_score: 0.8488\n",
            "Epoch 31/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3865 - acc: 0.8406 - precision: 0.8236 - recall: 0.8667 - f1_score: 0.8446 - val_loss: 0.3780 - val_acc: 0.8435 - val_precision: 0.8193 - val_recall: 0.8816 - val_f1_score: 0.8493\n",
            "Epoch 32/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3857 - acc: 0.8409 - precision: 0.8228 - recall: 0.8690 - f1_score: 0.8452 - val_loss: 0.3771 - val_acc: 0.8454 - val_precision: 0.8287 - val_recall: 0.8712 - val_f1_score: 0.8494\n",
            "Epoch 33/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3849 - acc: 0.8404 - precision: 0.8226 - recall: 0.8679 - f1_score: 0.8446 - val_loss: 0.3753 - val_acc: 0.8459 - val_precision: 0.8281 - val_recall: 0.8733 - val_f1_score: 0.8501\n",
            "Epoch 34/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3841 - acc: 0.8421 - precision: 0.8234 - recall: 0.8708 - f1_score: 0.8465 - val_loss: 0.3755 - val_acc: 0.8474 - val_precision: 0.8342 - val_recall: 0.8673 - val_f1_score: 0.8505\n",
            "Epoch 35/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3831 - acc: 0.8417 - precision: 0.8238 - recall: 0.8692 - f1_score: 0.8459 - val_loss: 0.3749 - val_acc: 0.8448 - val_precision: 0.8221 - val_recall: 0.8804 - val_f1_score: 0.8503\n",
            "Epoch 36/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3828 - acc: 0.8424 - precision: 0.8226 - recall: 0.8731 - f1_score: 0.8471 - val_loss: 0.3740 - val_acc: 0.8490 - val_precision: 0.8342 - val_recall: 0.8715 - val_f1_score: 0.8524\n",
            "Epoch 37/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3819 - acc: 0.8421 - precision: 0.8233 - recall: 0.8712 - f1_score: 0.8466 - val_loss: 0.3740 - val_acc: 0.8483 - val_precision: 0.8388 - val_recall: 0.8626 - val_f1_score: 0.8505\n",
            "Epoch 38/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3813 - acc: 0.8430 - precision: 0.8255 - recall: 0.8700 - f1_score: 0.8471 - val_loss: 0.3736 - val_acc: 0.8451 - val_precision: 0.8192 - val_recall: 0.8861 - val_f1_score: 0.8513\n",
            "Epoch 39/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3804 - acc: 0.8426 - precision: 0.8234 - recall: 0.8723 - f1_score: 0.8471 - val_loss: 0.3719 - val_acc: 0.8489 - val_precision: 0.8298 - val_recall: 0.8781 - val_f1_score: 0.8533\n",
            "Epoch 40/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3799 - acc: 0.8434 - precision: 0.8237 - recall: 0.8738 - f1_score: 0.8480 - val_loss: 0.3714 - val_acc: 0.8490 - val_precision: 0.8330 - val_recall: 0.8733 - val_f1_score: 0.8527\n",
            "Epoch 41/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3793 - acc: 0.8434 - precision: 0.8236 - recall: 0.8739 - f1_score: 0.8480 - val_loss: 0.3713 - val_acc: 0.8490 - val_precision: 0.8350 - val_recall: 0.8703 - val_f1_score: 0.8523\n",
            "Epoch 42/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3788 - acc: 0.8438 - precision: 0.8243 - recall: 0.8739 - f1_score: 0.8484 - val_loss: 0.3706 - val_acc: 0.8493 - val_precision: 0.8341 - val_recall: 0.8724 - val_f1_score: 0.8528\n",
            "Epoch 43/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3778 - acc: 0.8439 - precision: 0.8249 - recall: 0.8732 - f1_score: 0.8483 - val_loss: 0.3701 - val_acc: 0.8489 - val_precision: 0.8313 - val_recall: 0.8757 - val_f1_score: 0.8529\n",
            "Epoch 44/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3774 - acc: 0.8446 - precision: 0.8243 - recall: 0.8758 - f1_score: 0.8493 - val_loss: 0.3702 - val_acc: 0.8489 - val_precision: 0.8378 - val_recall: 0.8655 - val_f1_score: 0.8514\n",
            "Epoch 45/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3768 - acc: 0.8457 - precision: 0.8255 - recall: 0.8766 - f1_score: 0.8503 - val_loss: 0.3688 - val_acc: 0.8498 - val_precision: 0.8316 - val_recall: 0.8775 - val_f1_score: 0.8539\n",
            "Epoch 46/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3761 - acc: 0.8448 - precision: 0.8248 - recall: 0.8755 - f1_score: 0.8494 - val_loss: 0.3684 - val_acc: 0.8496 - val_precision: 0.8312 - val_recall: 0.8778 - val_f1_score: 0.8538\n",
            "Epoch 47/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3753 - acc: 0.8454 - precision: 0.8254 - recall: 0.8761 - f1_score: 0.8500 - val_loss: 0.3697 - val_acc: 0.8499 - val_precision: 0.8405 - val_recall: 0.8640 - val_f1_score: 0.8521\n",
            "Epoch 48/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3751 - acc: 0.8454 - precision: 0.8251 - recall: 0.8766 - f1_score: 0.8501 - val_loss: 0.3674 - val_acc: 0.8495 - val_precision: 0.8340 - val_recall: 0.8730 - val_f1_score: 0.8530\n",
            "Epoch 49/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3746 - acc: 0.8455 - precision: 0.8247 - recall: 0.8774 - f1_score: 0.8503 - val_loss: 0.3672 - val_acc: 0.8514 - val_precision: 0.8382 - val_recall: 0.8712 - val_f1_score: 0.8544\n",
            "Epoch 50/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3740 - acc: 0.8459 - precision: 0.8249 - recall: 0.8782 - f1_score: 0.8507 - val_loss: 0.3672 - val_acc: 0.8493 - val_precision: 0.8326 - val_recall: 0.8748 - val_f1_score: 0.8532\n",
            "Epoch 51/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3738 - acc: 0.8456 - precision: 0.8256 - recall: 0.8764 - f1_score: 0.8502 - val_loss: 0.3666 - val_acc: 0.8496 - val_precision: 0.8277 - val_recall: 0.8834 - val_f1_score: 0.8546\n",
            "Epoch 52/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3728 - acc: 0.8464 - precision: 0.8254 - recall: 0.8786 - f1_score: 0.8512 - val_loss: 0.3667 - val_acc: 0.8474 - val_precision: 0.8284 - val_recall: 0.8766 - val_f1_score: 0.8518\n",
            "Epoch 53/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3729 - acc: 0.8457 - precision: 0.8240 - recall: 0.8791 - f1_score: 0.8507 - val_loss: 0.3656 - val_acc: 0.8504 - val_precision: 0.8335 - val_recall: 0.8760 - val_f1_score: 0.8542\n",
            "Epoch 54/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3720 - acc: 0.8459 - precision: 0.8247 - recall: 0.8785 - f1_score: 0.8508 - val_loss: 0.3653 - val_acc: 0.8504 - val_precision: 0.8329 - val_recall: 0.8769 - val_f1_score: 0.8543\n",
            "Epoch 55/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3718 - acc: 0.8462 - precision: 0.8251 - recall: 0.8786 - f1_score: 0.8510 - val_loss: 0.3660 - val_acc: 0.8496 - val_precision: 0.8282 - val_recall: 0.8825 - val_f1_score: 0.8545\n",
            "Epoch 56/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3712 - acc: 0.8455 - precision: 0.8239 - recall: 0.8788 - f1_score: 0.8505 - val_loss: 0.3657 - val_acc: 0.8498 - val_precision: 0.8312 - val_recall: 0.8781 - val_f1_score: 0.8540\n",
            "Epoch 57/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3706 - acc: 0.8466 - precision: 0.8252 - recall: 0.8793 - f1_score: 0.8514 - val_loss: 0.3648 - val_acc: 0.8501 - val_precision: 0.8341 - val_recall: 0.8742 - val_f1_score: 0.8537\n",
            "Epoch 58/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3703 - acc: 0.8464 - precision: 0.8254 - recall: 0.8787 - f1_score: 0.8512 - val_loss: 0.3642 - val_acc: 0.8517 - val_precision: 0.8281 - val_recall: 0.8879 - val_f1_score: 0.8570\n",
            "Epoch 59/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3699 - acc: 0.8470 - precision: 0.8259 - recall: 0.8794 - f1_score: 0.8518 - val_loss: 0.3654 - val_acc: 0.8480 - val_precision: 0.8205 - val_recall: 0.8912 - val_f1_score: 0.8544\n",
            "Epoch 60/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3693 - acc: 0.8471 - precision: 0.8247 - recall: 0.8814 - f1_score: 0.8521 - val_loss: 0.3646 - val_acc: 0.8504 - val_precision: 0.8337 - val_recall: 0.8757 - val_f1_score: 0.8542\n",
            "Epoch 61/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3691 - acc: 0.8471 - precision: 0.8250 - recall: 0.8809 - f1_score: 0.8521 - val_loss: 0.3640 - val_acc: 0.8501 - val_precision: 0.8349 - val_recall: 0.8730 - val_f1_score: 0.8535\n",
            "Epoch 62/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3687 - acc: 0.8477 - precision: 0.8263 - recall: 0.8803 - f1_score: 0.8525 - val_loss: 0.3637 - val_acc: 0.8486 - val_precision: 0.8235 - val_recall: 0.8876 - val_f1_score: 0.8544\n",
            "Epoch 63/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3679 - acc: 0.8483 - precision: 0.8260 - recall: 0.8823 - f1_score: 0.8532 - val_loss: 0.3637 - val_acc: 0.8486 - val_precision: 0.8200 - val_recall: 0.8936 - val_f1_score: 0.8552\n",
            "Epoch 64/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3675 - acc: 0.8477 - precision: 0.8249 - recall: 0.8828 - f1_score: 0.8528 - val_loss: 0.3629 - val_acc: 0.8502 - val_precision: 0.8317 - val_recall: 0.8784 - val_f1_score: 0.8544\n",
            "Epoch 65/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3672 - acc: 0.8481 - precision: 0.8266 - recall: 0.8808 - f1_score: 0.8529 - val_loss: 0.3637 - val_acc: 0.8498 - val_precision: 0.8316 - val_recall: 0.8775 - val_f1_score: 0.8539\n",
            "Epoch 66/100\n",
            "26811/26811 [==============================] - 1s 25us/step - loss: 0.3669 - acc: 0.8488 - precision: 0.8261 - recall: 0.8835 - f1_score: 0.8538 - val_loss: 0.3616 - val_acc: 0.8504 - val_precision: 0.8295 - val_recall: 0.8822 - val_f1_score: 0.8551\n",
            "Epoch 67/100\n",
            "26811/26811 [==============================] - 1s 26us/step - loss: 0.3666 - acc: 0.8486 - precision: 0.8265 - recall: 0.8823 - f1_score: 0.8535 - val_loss: 0.3624 - val_acc: 0.8495 - val_precision: 0.8215 - val_recall: 0.8933 - val_f1_score: 0.8559\n",
            "Epoch 68/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3660 - acc: 0.8492 - precision: 0.8273 - recall: 0.8827 - f1_score: 0.8541 - val_loss: 0.3615 - val_acc: 0.8513 - val_precision: 0.8309 - val_recall: 0.8822 - val_f1_score: 0.8558\n",
            "Epoch 69/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3655 - acc: 0.8499 - precision: 0.8274 - recall: 0.8841 - f1_score: 0.8548 - val_loss: 0.3632 - val_acc: 0.8477 - val_precision: 0.8159 - val_recall: 0.8983 - val_f1_score: 0.8551\n",
            "Epoch 70/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3652 - acc: 0.8493 - precision: 0.8253 - recall: 0.8860 - f1_score: 0.8546 - val_loss: 0.3614 - val_acc: 0.8511 - val_precision: 0.8305 - val_recall: 0.8825 - val_f1_score: 0.8557\n",
            "Epoch 71/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3645 - acc: 0.8501 - precision: 0.8272 - recall: 0.8850 - f1_score: 0.8551 - val_loss: 0.3620 - val_acc: 0.8508 - val_precision: 0.8314 - val_recall: 0.8804 - val_f1_score: 0.8552\n",
            "Epoch 72/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3643 - acc: 0.8501 - precision: 0.8267 - recall: 0.8858 - f1_score: 0.8552 - val_loss: 0.3619 - val_acc: 0.8514 - val_precision: 0.8288 - val_recall: 0.8861 - val_f1_score: 0.8565\n",
            "Epoch 73/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3638 - acc: 0.8506 - precision: 0.8272 - recall: 0.8863 - f1_score: 0.8557 - val_loss: 0.3614 - val_acc: 0.8501 - val_precision: 0.8267 - val_recall: 0.8861 - val_f1_score: 0.8554\n",
            "Epoch 74/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3633 - acc: 0.8500 - precision: 0.8264 - recall: 0.8862 - f1_score: 0.8552 - val_loss: 0.3616 - val_acc: 0.8505 - val_precision: 0.8270 - val_recall: 0.8867 - val_f1_score: 0.8558\n",
            "Epoch 75/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3632 - acc: 0.8513 - precision: 0.8276 - recall: 0.8874 - f1_score: 0.8565 - val_loss: 0.3603 - val_acc: 0.8489 - val_precision: 0.8269 - val_recall: 0.8828 - val_f1_score: 0.8539\n",
            "Epoch 76/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3628 - acc: 0.8508 - precision: 0.8270 - recall: 0.8873 - f1_score: 0.8561 - val_loss: 0.3638 - val_acc: 0.8483 - val_precision: 0.8345 - val_recall: 0.8691 - val_f1_score: 0.8515\n",
            "Epoch 77/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3623 - acc: 0.8519 - precision: 0.8289 - recall: 0.8867 - f1_score: 0.8568 - val_loss: 0.3602 - val_acc: 0.8516 - val_precision: 0.8270 - val_recall: 0.8894 - val_f1_score: 0.8571\n",
            "Epoch 78/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3620 - acc: 0.8514 - precision: 0.8277 - recall: 0.8875 - f1_score: 0.8565 - val_loss: 0.3605 - val_acc: 0.8490 - val_precision: 0.8237 - val_recall: 0.8885 - val_f1_score: 0.8548\n",
            "Epoch 79/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3617 - acc: 0.8518 - precision: 0.8276 - recall: 0.8887 - f1_score: 0.8571 - val_loss: 0.3592 - val_acc: 0.8502 - val_precision: 0.8235 - val_recall: 0.8918 - val_f1_score: 0.8563\n",
            "Epoch 80/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3614 - acc: 0.8511 - precision: 0.8276 - recall: 0.8869 - f1_score: 0.8562 - val_loss: 0.3585 - val_acc: 0.8525 - val_precision: 0.8336 - val_recall: 0.8810 - val_f1_score: 0.8566\n",
            "Epoch 81/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3608 - acc: 0.8518 - precision: 0.8288 - recall: 0.8867 - f1_score: 0.8568 - val_loss: 0.3590 - val_acc: 0.8499 - val_precision: 0.8204 - val_recall: 0.8962 - val_f1_score: 0.8567\n",
            "Epoch 82/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3605 - acc: 0.8521 - precision: 0.8283 - recall: 0.8882 - f1_score: 0.8572 - val_loss: 0.3589 - val_acc: 0.8486 - val_precision: 0.8177 - val_recall: 0.8974 - val_f1_score: 0.8557\n",
            "Epoch 83/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3601 - acc: 0.8520 - precision: 0.8279 - recall: 0.8888 - f1_score: 0.8573 - val_loss: 0.3590 - val_acc: 0.8501 - val_precision: 0.8235 - val_recall: 0.8915 - val_f1_score: 0.8561\n",
            "Epoch 84/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3594 - acc: 0.8528 - precision: 0.8290 - recall: 0.8889 - f1_score: 0.8579 - val_loss: 0.3612 - val_acc: 0.8490 - val_precision: 0.8155 - val_recall: 0.9025 - val_f1_score: 0.8568\n",
            "Epoch 85/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3593 - acc: 0.8524 - precision: 0.8282 - recall: 0.8892 - f1_score: 0.8576 - val_loss: 0.3607 - val_acc: 0.8508 - val_precision: 0.8424 - val_recall: 0.8634 - val_f1_score: 0.8528\n",
            "Epoch 86/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3589 - acc: 0.8524 - precision: 0.8293 - recall: 0.8875 - f1_score: 0.8574 - val_loss: 0.3591 - val_acc: 0.8508 - val_precision: 0.8327 - val_recall: 0.8784 - val_f1_score: 0.8549\n",
            "Epoch 87/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3584 - acc: 0.8531 - precision: 0.8292 - recall: 0.8894 - f1_score: 0.8582 - val_loss: 0.3590 - val_acc: 0.8517 - val_precision: 0.8258 - val_recall: 0.8918 - val_f1_score: 0.8575\n",
            "Epoch 88/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3582 - acc: 0.8533 - precision: 0.8292 - recall: 0.8900 - f1_score: 0.8585 - val_loss: 0.3569 - val_acc: 0.8532 - val_precision: 0.8308 - val_recall: 0.8873 - val_f1_score: 0.8581\n",
            "Epoch 89/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3578 - acc: 0.8533 - precision: 0.8286 - recall: 0.8908 - f1_score: 0.8586 - val_loss: 0.3574 - val_acc: 0.8526 - val_precision: 0.8347 - val_recall: 0.8795 - val_f1_score: 0.8566\n",
            "Epoch 90/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3577 - acc: 0.8525 - precision: 0.8282 - recall: 0.8894 - f1_score: 0.8577 - val_loss: 0.3601 - val_acc: 0.8520 - val_precision: 0.8392 - val_recall: 0.8712 - val_f1_score: 0.8549\n",
            "Epoch 91/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3572 - acc: 0.8543 - precision: 0.8305 - recall: 0.8901 - f1_score: 0.8593 - val_loss: 0.3573 - val_acc: 0.8490 - val_precision: 0.8199 - val_recall: 0.8948 - val_f1_score: 0.8557\n",
            "Epoch 92/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3569 - acc: 0.8529 - precision: 0.8286 - recall: 0.8898 - f1_score: 0.8581 - val_loss: 0.3576 - val_acc: 0.8508 - val_precision: 0.8315 - val_recall: 0.8801 - val_f1_score: 0.8552\n",
            "Epoch 93/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3566 - acc: 0.8536 - precision: 0.8291 - recall: 0.8908 - f1_score: 0.8589 - val_loss: 0.3557 - val_acc: 0.8541 - val_precision: 0.8346 - val_recall: 0.8834 - val_f1_score: 0.8583\n",
            "Epoch 94/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3558 - acc: 0.8541 - precision: 0.8289 - recall: 0.8922 - f1_score: 0.8594 - val_loss: 0.3559 - val_acc: 0.8535 - val_precision: 0.8339 - val_recall: 0.8831 - val_f1_score: 0.8578\n",
            "Epoch 95/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3555 - acc: 0.8539 - precision: 0.8301 - recall: 0.8899 - f1_score: 0.8589 - val_loss: 0.3564 - val_acc: 0.8501 - val_precision: 0.8213 - val_recall: 0.8951 - val_f1_score: 0.8566\n",
            "Epoch 96/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3553 - acc: 0.8540 - precision: 0.8294 - recall: 0.8911 - f1_score: 0.8592 - val_loss: 0.3544 - val_acc: 0.8520 - val_precision: 0.8299 - val_recall: 0.8858 - val_f1_score: 0.8569\n",
            "Epoch 97/100\n",
            "26811/26811 [==============================] - 1s 27us/step - loss: 0.3550 - acc: 0.8542 - precision: 0.8298 - recall: 0.8910 - f1_score: 0.8593 - val_loss: 0.3556 - val_acc: 0.8547 - val_precision: 0.8371 - val_recall: 0.8810 - val_f1_score: 0.8585\n",
            "Epoch 98/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3544 - acc: 0.8542 - precision: 0.8295 - recall: 0.8917 - f1_score: 0.8594 - val_loss: 0.3552 - val_acc: 0.8520 - val_precision: 0.8275 - val_recall: 0.8897 - val_f1_score: 0.8575\n",
            "Epoch 99/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3541 - acc: 0.8542 - precision: 0.8299 - recall: 0.8911 - f1_score: 0.8594 - val_loss: 0.3559 - val_acc: 0.8499 - val_precision: 0.8197 - val_recall: 0.8974 - val_f1_score: 0.8568\n",
            "Epoch 100/100\n",
            "26811/26811 [==============================] - 1s 28us/step - loss: 0.3539 - acc: 0.8542 - precision: 0.8295 - recall: 0.8917 - f1_score: 0.8594 - val_loss: 0.3556 - val_acc: 0.8508 - val_precision: 0.8242 - val_recall: 0.8921 - val_f1_score: 0.8568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xpGzBlnxyA4",
        "colab_type": "code",
        "outputId": "5fd38414-fd21-429f-f5a0-0d60774f9d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot model loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOZKSEfD_5K",
        "colab_type": "code",
        "outputId": "6c0e8659-4c4c-437d-a297-a7105a257acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot model acuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlCrT/wNKtMN1EGzP3wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CIT6vRWk5Ls",
        "colab_type": "code",
        "outputId": "1da824dd-0b6f-4bb7-8cb4-b7adcfcf41e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "results = model.evaluate(X_val, Y_val)\n",
        "\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5395/5395 [==============================] - 0s 25us/step\n",
            "test loss, test acc: [0.48727703328702715, 0.7916589434882686, 0.8511355970125672, 0.8912173298589307, 0.8707153859392599]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLHgr2-flkuV",
        "colab_type": "code",
        "outputId": "6f5cabfa-00d7-4419-d435-0ad4ea0f325b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Y_val_true = [ enc[int(max(enc))] for enc in Y_val]\n",
        "\n",
        "print( 'Classification report\\n', classification_report(Y_val_true, model.predict_classes(X_val)) )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.89      0.87      4247\n",
            "         1.0       0.51      0.42      0.46      1148\n",
            "\n",
            "    accuracy                           0.79      5395\n",
            "   macro avg       0.68      0.66      0.67      5395\n",
            "weighted avg       0.78      0.79      0.78      5395\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyrMuDtYBVNO",
        "colab_type": "code",
        "outputId": "b541ab58-32ab-40fa-d197-091a85ad9ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict on test\n",
        "\n",
        "Y_test_pred = model.predict_classes(X_test)\n",
        "print(Y_test_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}