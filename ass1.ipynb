{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzi27/adv-ml-assignment1/blob/master/ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABVe6x05udwR",
        "colab_type": "text"
      },
      "source": [
        "# Amrani Hamza - 807386"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypQq2FN-rSDe",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsPy5ahXujZt",
        "colab_type": "code",
        "outputId": "6ad9046b-de40-4e77-a477-3e01dea73a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url_train = 'https://raw.githubusercontent.com/hamzi27/adv-ml-assignment1/master/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/hamzi27/adv-ml-assignment1/master/test.csv'\n",
        "\n",
        "train = pd.read_csv(url_train)\n",
        "test = pd.read_csv(url_test)\n",
        "\n",
        "print(train.head())\n",
        "print(\"Training set data shape: \", train.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   LIMIT_BAL  SEX  EDUCATION  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n",
            "0    20000.0    2          2  ...       0.0       0.0                           1\n",
            "1   120000.0    2          2  ...       0.0    2000.0                           1\n",
            "2    90000.0    2          2  ...    1000.0    5000.0                           0\n",
            "3    50000.0    2          2  ...    1069.0    1000.0                           0\n",
            "4    50000.0    1          2  ...     689.0     679.0                           0\n",
            "\n",
            "[5 rows x 24 columns]\n",
            "Training set data shape:  (27000, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0a7BVVIpvzO",
        "colab_type": "text"
      },
      "source": [
        "# Analysis on data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlQ4_442smWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U pandas_profiling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62TFvroXpyiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas_profiling\n",
        "\n",
        "# train.profile_report(style={'full_width':True})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb7jLOZtuVMH",
        "colab_type": "text"
      },
      "source": [
        "# Removing columns highly correlated and duplicates rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL_qakFeuc7N",
        "colab_type": "code",
        "outputId": "ed04a66f-b806-46aa-d3e7-48ba580ec20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Drop of duplicates rows\n",
        "train = train.drop_duplicates()\n",
        "test = test.drop_duplicates()\n",
        "\n",
        "# Drop columns lowly correlated to target\n",
        "\n",
        "train.drop(columns=['AGE','EDUCATION','LIMIT_BAL','MARRIAGE','SEX','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6'], axis=1, inplace=True)\n",
        "test.drop(columns=['AGE','EDUCATION','LIMIT_BAL','MARRIAGE','SEX','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6'], axis=1, inplace=True)\n",
        "\n",
        "print(\"Train shape: \", train.shape)\n",
        "print(\"Number of 0: \", sum(train['default.payment.next.month']==0))\n",
        "print(\"Number of 1: \", sum(train['default.payment.next.month']==1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape:  (26973, 13)\n",
            "Number of 0:  21004\n",
            "Number of 1:  5969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9YrxFoahyvI",
        "colab_type": "text"
      },
      "source": [
        "# Split train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNQk-sc-h1-A",
        "colab_type": "code",
        "outputId": "82fcc673-c888-41f4-ff84-ef41e1534ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, validation = train_test_split( train,test_size=0.2)\n",
        "\n",
        "print(\"Train: \", train.shape)\n",
        "\n",
        "num_0 = sum(train['default.payment.next.month']==0)\n",
        "num_1 = sum(train['default.payment.next.month']==1)\n",
        "print(\"Number of 0: \", num_0)\n",
        "print(\"Number of 1: \", num_1)\n",
        "\n",
        "print(\"\\nValidation: \", validation.shape)\n",
        "print(\"Number of 0: \", sum(validation['default.payment.next.month']==0))\n",
        "print(\"Number of 1: \", sum(validation['default.payment.next.month']==1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (21578, 13)\n",
            "Number of 0:  16756\n",
            "Number of 1:  4822\n",
            "\n",
            "Validation:  (5395, 13)\n",
            "Number of 0:  4248\n",
            "Number of 1:  1147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HktIjzJ01HNV",
        "colab_type": "text"
      },
      "source": [
        "# Over-sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ISu_VF31NH",
        "colab_type": "code",
        "outputId": "aa165440-ae28-40e8-ba66-d58f2704e458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from numpy.random import random_sample\n",
        "\n",
        "train_1 = train[train['default.payment.next.month']==1]\n",
        "\n",
        "values = [train_1[column].value_counts(normalize=True).keys().tolist() for column in train_1.columns[:-1]]\n",
        "probabilities = [train_1[column].value_counts(normalize=True).tolist() for column in train_1.columns[:-1]]\n",
        "\n",
        "verify = {}\n",
        "for index, row in train_1.iterrows():\n",
        "    verify [str(row.values)]=1\n",
        "    \n",
        "sample_rows = []\n",
        "for _ in range(num_0-num_1):\n",
        "  while True:\n",
        "    sample_row = []\n",
        "    \n",
        "    for i in range(len(values)):\n",
        "      bins = np.add.accumulate(probabilities[i])\n",
        "      sample_of_column = [values[i][n] for n in np.digitize(random_sample(1), bins)]\n",
        "      sample_row.extend(sample_of_column)\n",
        "    sample_row.extend([1])\n",
        "    \n",
        "    try:\n",
        "      verify[str(sample_row)]\n",
        "    except:\n",
        "      verify[str(sample_row)] = 1\n",
        "      break\n",
        "  \n",
        "  sample_rows.append(sample_row)\n",
        "\n",
        "train_oversample = pd.DataFrame(sample_rows, columns = train.columns) \n",
        "train = train.append(train_oversample, ignore_index=True)\n",
        "\n",
        "print(train.head())\n",
        "\n",
        "print(\"Ended over-sample on train!\")\n",
        "print(\"Number of 0: \", sum(train['default.payment.next.month']==0))\n",
        "print(\"Number of 1: \", sum(train['default.payment.next.month']==1))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PAY_0  PAY_2  PAY_3  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n",
            "0     -1     -1     -1  ...       0.0    1593.0                           0\n",
            "1      0      0      0  ...    5155.0    4145.0                           0\n",
            "2      2      2      0  ...   13600.0   13600.0                           1\n",
            "3      0     -1      0  ...    9000.0    9014.0                           0\n",
            "4      0      0      0  ...       0.0    5000.0                           0\n",
            "\n",
            "[5 rows x 13 columns]\n",
            "Ended over-sample on train!\n",
            "Number of 0:  16756\n",
            "Number of 1:  16756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRgLhpASlgK",
        "colab_type": "text"
      },
      "source": [
        "# Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB7BcrYNSpgw",
        "colab_type": "code",
        "outputId": "5fc3fbed-20ef-4dba-f62c-4a978b395d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def load_data(df, train=True):\n",
        "    X = df.values.copy()\n",
        "    if train:\n",
        "        np.random.shuffle(X)  \n",
        "        X, labels = X[:, 0:-1].astype(np.float32), X[:, -1]\n",
        "        return X, labels\n",
        "    else:\n",
        "        X, ids = X[:, 0:].astype(np.float32), X[:, 0].astype(str)\n",
        "        return X, ids\n",
        "\n",
        "\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    \"\"\"Encode labels with values among 0 and `n-classes-1`\"\"\"\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = np_utils.to_categorical(y)\n",
        "    return y, encoder\n",
        "  \n",
        "\n",
        "X_train, Y_train = load_data(train, train=True)\n",
        "X_val, Y_val = load_data(validation, train=True)\n",
        "X_test, Y_test = load_data(test, train=False)\n",
        "  \n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "Y_train, encoder = preprocess_labels(Y_train)\n",
        "Y_val, encoder_val = preprocess_labels(Y_val)\n",
        "\n",
        "nb_classes = Y_train.shape[1]\n",
        "dims = X_train.shape[1]\n",
        "\n",
        "print(nb_classes, 'classes')\n",
        "print(dims, 'dims')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 classes\n",
            "12 dims\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOsKfsy4Ta5C",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTA4XjQwBF96",
        "colab_type": "code",
        "outputId": "6f5ad6e8-31cc-4697-f167-483d798ae89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install keras_metrics"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3OAAJsOTeyH",
        "colab_type": "code",
        "outputId": "d9e95826-4360-4486-aba8-cff1f5c9c5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers.core import Activation, Dropout\n",
        "import keras_metrics\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(dims,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics =[\"accuracy\", keras_metrics.binary_precision(), keras_metrics.binary_recall(), keras_metrics.binary_f1_score()])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 64)                832       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 2,978\n",
            "Trainable params: 2,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umdZhxDfC4mX",
        "colab_type": "code",
        "outputId": "da1e6122-aedb-4ca5-a998-c47800216c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=True) \n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 26809 samples, validate on 6703 samples\n",
            "Epoch 1/100\n",
            "26809/26809 [==============================] - 1s 27us/step - loss: 0.6261 - acc: 0.7155 - precision: 0.7130 - recall: 0.7253 - f1_score: 0.7191 - val_loss: 0.5829 - val_acc: 0.7676 - val_precision: 0.7554 - val_recall: 0.7793 - val_f1_score: 0.7672\n",
            "Epoch 2/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.5466 - acc: 0.7911 - precision: 0.7868 - recall: 0.8011 - f1_score: 0.7939 - val_loss: 0.5389 - val_acc: 0.7856 - val_precision: 0.7720 - val_recall: 0.7999 - val_f1_score: 0.7857\n",
            "Epoch 3/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.5078 - acc: 0.8003 - precision: 0.7962 - recall: 0.8093 - f1_score: 0.8027 - val_loss: 0.5098 - val_acc: 0.7913 - val_precision: 0.7829 - val_recall: 0.7960 - val_f1_score: 0.7894\n",
            "Epoch 4/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4806 - acc: 0.8047 - precision: 0.8049 - recall: 0.8065 - f1_score: 0.8057 - val_loss: 0.4882 - val_acc: 0.7952 - val_precision: 0.7911 - val_recall: 0.7923 - val_f1_score: 0.7917\n",
            "Epoch 5/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.4604 - acc: 0.8076 - precision: 0.8109 - recall: 0.8044 - f1_score: 0.8076 - val_loss: 0.4727 - val_acc: 0.7982 - val_precision: 0.7940 - val_recall: 0.7957 - val_f1_score: 0.7948\n",
            "Epoch 6/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4459 - acc: 0.8104 - precision: 0.8152 - recall: 0.8049 - f1_score: 0.8100 - val_loss: 0.4615 - val_acc: 0.8010 - val_precision: 0.7986 - val_recall: 0.7957 - val_f1_score: 0.7971\n",
            "Epoch 7/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4357 - acc: 0.8115 - precision: 0.8178 - recall: 0.8037 - f1_score: 0.8107 - val_loss: 0.4536 - val_acc: 0.8013 - val_precision: 0.7953 - val_recall: 0.8021 - val_f1_score: 0.7987\n",
            "Epoch 8/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4284 - acc: 0.8128 - precision: 0.8168 - recall: 0.8086 - f1_score: 0.8127 - val_loss: 0.4478 - val_acc: 0.8026 - val_precision: 0.8015 - val_recall: 0.7954 - val_f1_score: 0.7984\n",
            "Epoch 9/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4230 - acc: 0.8138 - precision: 0.8175 - recall: 0.8098 - f1_score: 0.8137 - val_loss: 0.4435 - val_acc: 0.8028 - val_precision: 0.7970 - val_recall: 0.8033 - val_f1_score: 0.8001\n",
            "Epoch 10/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4191 - acc: 0.8135 - precision: 0.8152 - recall: 0.8128 - f1_score: 0.8140 - val_loss: 0.4398 - val_acc: 0.8055 - val_precision: 0.8006 - val_recall: 0.8045 - val_f1_score: 0.8025\n",
            "Epoch 11/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.4161 - acc: 0.8152 - precision: 0.8164 - recall: 0.8154 - f1_score: 0.8159 - val_loss: 0.4371 - val_acc: 0.8075 - val_precision: 0.7998 - val_recall: 0.8115 - val_f1_score: 0.8056\n",
            "Epoch 12/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4136 - acc: 0.8169 - precision: 0.8160 - recall: 0.8205 - f1_score: 0.8182 - val_loss: 0.4346 - val_acc: 0.8099 - val_precision: 0.8019 - val_recall: 0.8145 - val_f1_score: 0.8081\n",
            "Epoch 13/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.4114 - acc: 0.8181 - precision: 0.8181 - recall: 0.8202 - f1_score: 0.8191 - val_loss: 0.4328 - val_acc: 0.8126 - val_precision: 0.8017 - val_recall: 0.8221 - val_f1_score: 0.8118\n",
            "Epoch 14/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4097 - acc: 0.8206 - precision: 0.8179 - recall: 0.8268 - f1_score: 0.8223 - val_loss: 0.4313 - val_acc: 0.8137 - val_precision: 0.8053 - val_recall: 0.8188 - val_f1_score: 0.8120\n",
            "Epoch 15/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4081 - acc: 0.8208 - precision: 0.8190 - recall: 0.8256 - f1_score: 0.8223 - val_loss: 0.4303 - val_acc: 0.8164 - val_precision: 0.8033 - val_recall: 0.8294 - val_f1_score: 0.8161\n",
            "Epoch 16/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4068 - acc: 0.8216 - precision: 0.8180 - recall: 0.8291 - f1_score: 0.8235 - val_loss: 0.4284 - val_acc: 0.8164 - val_precision: 0.8065 - val_recall: 0.8239 - val_f1_score: 0.8151\n",
            "Epoch 17/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4054 - acc: 0.8228 - precision: 0.8197 - recall: 0.8295 - f1_score: 0.8246 - val_loss: 0.4275 - val_acc: 0.8166 - val_precision: 0.8034 - val_recall: 0.8300 - val_f1_score: 0.8165\n",
            "Epoch 18/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.4043 - acc: 0.8236 - precision: 0.8193 - recall: 0.8321 - f1_score: 0.8257 - val_loss: 0.4272 - val_acc: 0.8168 - val_precision: 0.8017 - val_recall: 0.8333 - val_f1_score: 0.8172\n",
            "Epoch 19/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4033 - acc: 0.8251 - precision: 0.8198 - recall: 0.8354 - f1_score: 0.8275 - val_loss: 0.4256 - val_acc: 0.8177 - val_precision: 0.8043 - val_recall: 0.8312 - val_f1_score: 0.8176\n",
            "Epoch 20/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4020 - acc: 0.8256 - precision: 0.8205 - recall: 0.8355 - f1_score: 0.8279 - val_loss: 0.4247 - val_acc: 0.8174 - val_precision: 0.8039 - val_recall: 0.8312 - val_f1_score: 0.8173\n",
            "Epoch 21/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4012 - acc: 0.8258 - precision: 0.8198 - recall: 0.8372 - f1_score: 0.8284 - val_loss: 0.4234 - val_acc: 0.8174 - val_precision: 0.8066 - val_recall: 0.8267 - val_f1_score: 0.8165\n",
            "Epoch 22/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.4002 - acc: 0.8263 - precision: 0.8213 - recall: 0.8361 - f1_score: 0.8286 - val_loss: 0.4235 - val_acc: 0.8192 - val_precision: 0.8055 - val_recall: 0.8333 - val_f1_score: 0.8192\n",
            "Epoch 23/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3994 - acc: 0.8271 - precision: 0.8215 - recall: 0.8378 - f1_score: 0.8295 - val_loss: 0.4218 - val_acc: 0.8186 - val_precision: 0.8052 - val_recall: 0.8321 - val_f1_score: 0.8185\n",
            "Epoch 24/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3986 - acc: 0.8274 - precision: 0.8216 - recall: 0.8384 - f1_score: 0.8299 - val_loss: 0.4207 - val_acc: 0.8195 - val_precision: 0.8074 - val_recall: 0.8309 - val_f1_score: 0.8190\n",
            "Epoch 25/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3977 - acc: 0.8283 - precision: 0.8227 - recall: 0.8389 - f1_score: 0.8307 - val_loss: 0.4204 - val_acc: 0.8190 - val_precision: 0.8036 - val_recall: 0.8361 - val_f1_score: 0.8195\n",
            "Epoch 26/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3969 - acc: 0.8288 - precision: 0.8216 - recall: 0.8418 - f1_score: 0.8316 - val_loss: 0.4190 - val_acc: 0.8187 - val_precision: 0.8064 - val_recall: 0.8306 - val_f1_score: 0.8183\n",
            "Epoch 27/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3962 - acc: 0.8296 - precision: 0.8232 - recall: 0.8413 - f1_score: 0.8322 - val_loss: 0.4184 - val_acc: 0.8201 - val_precision: 0.8063 - val_recall: 0.8342 - val_f1_score: 0.8201\n",
            "Epoch 28/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3954 - acc: 0.8296 - precision: 0.8225 - recall: 0.8424 - f1_score: 0.8323 - val_loss: 0.4177 - val_acc: 0.8190 - val_precision: 0.8065 - val_recall: 0.8312 - val_f1_score: 0.8187\n",
            "Epoch 29/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3947 - acc: 0.8296 - precision: 0.8235 - recall: 0.8410 - f1_score: 0.8322 - val_loss: 0.4166 - val_acc: 0.8199 - val_precision: 0.8070 - val_recall: 0.8327 - val_f1_score: 0.8197\n",
            "Epoch 30/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3939 - acc: 0.8299 - precision: 0.8233 - recall: 0.8419 - f1_score: 0.8325 - val_loss: 0.4157 - val_acc: 0.8204 - val_precision: 0.8070 - val_recall: 0.8339 - val_f1_score: 0.8202\n",
            "Epoch 31/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3932 - acc: 0.8308 - precision: 0.8235 - recall: 0.8440 - f1_score: 0.8336 - val_loss: 0.4155 - val_acc: 0.8205 - val_precision: 0.8074 - val_recall: 0.8336 - val_f1_score: 0.8203\n",
            "Epoch 32/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3925 - acc: 0.8308 - precision: 0.8231 - recall: 0.8445 - f1_score: 0.8337 - val_loss: 0.4148 - val_acc: 0.8199 - val_precision: 0.8081 - val_recall: 0.8309 - val_f1_score: 0.8193\n",
            "Epoch 33/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3919 - acc: 0.8314 - precision: 0.8242 - recall: 0.8444 - f1_score: 0.8342 - val_loss: 0.4139 - val_acc: 0.8211 - val_precision: 0.8075 - val_recall: 0.8352 - val_f1_score: 0.8211\n",
            "Epoch 34/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3912 - acc: 0.8315 - precision: 0.8239 - recall: 0.8451 - f1_score: 0.8344 - val_loss: 0.4135 - val_acc: 0.8222 - val_precision: 0.8080 - val_recall: 0.8370 - val_f1_score: 0.8222\n",
            "Epoch 35/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3907 - acc: 0.8318 - precision: 0.8239 - recall: 0.8458 - f1_score: 0.8347 - val_loss: 0.4126 - val_acc: 0.8220 - val_precision: 0.8091 - val_recall: 0.8349 - val_f1_score: 0.8218\n",
            "Epoch 36/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3899 - acc: 0.8318 - precision: 0.8247 - recall: 0.8446 - f1_score: 0.8346 - val_loss: 0.4127 - val_acc: 0.8229 - val_precision: 0.8023 - val_recall: 0.8488 - val_f1_score: 0.8249\n",
            "Epoch 37/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3894 - acc: 0.8327 - precision: 0.8239 - recall: 0.8482 - f1_score: 0.8358 - val_loss: 0.4115 - val_acc: 0.8228 - val_precision: 0.8059 - val_recall: 0.8421 - val_f1_score: 0.8236\n",
            "Epoch 38/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3889 - acc: 0.8326 - precision: 0.8238 - recall: 0.8479 - f1_score: 0.8357 - val_loss: 0.4107 - val_acc: 0.8232 - val_precision: 0.8079 - val_recall: 0.8400 - val_f1_score: 0.8236\n",
            "Epoch 39/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3884 - acc: 0.8330 - precision: 0.8239 - recall: 0.8489 - f1_score: 0.8362 - val_loss: 0.4103 - val_acc: 0.8234 - val_precision: 0.8062 - val_recall: 0.8434 - val_f1_score: 0.8243\n",
            "Epoch 40/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3877 - acc: 0.8333 - precision: 0.8240 - recall: 0.8495 - f1_score: 0.8365 - val_loss: 0.4096 - val_acc: 0.8237 - val_precision: 0.8070 - val_recall: 0.8427 - val_f1_score: 0.8245\n",
            "Epoch 41/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3871 - acc: 0.8339 - precision: 0.8236 - recall: 0.8515 - f1_score: 0.8373 - val_loss: 0.4095 - val_acc: 0.8235 - val_precision: 0.8120 - val_recall: 0.8339 - val_f1_score: 0.8228\n",
            "Epoch 42/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3867 - acc: 0.8348 - precision: 0.8247 - recall: 0.8521 - f1_score: 0.8382 - val_loss: 0.4084 - val_acc: 0.8240 - val_precision: 0.8091 - val_recall: 0.8400 - val_f1_score: 0.8242\n",
            "Epoch 43/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3861 - acc: 0.8349 - precision: 0.8235 - recall: 0.8543 - f1_score: 0.8386 - val_loss: 0.4081 - val_acc: 0.8244 - val_precision: 0.8109 - val_recall: 0.8382 - val_f1_score: 0.8243\n",
            "Epoch 44/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3855 - acc: 0.8354 - precision: 0.8237 - recall: 0.8552 - f1_score: 0.8392 - val_loss: 0.4073 - val_acc: 0.8247 - val_precision: 0.8106 - val_recall: 0.8394 - val_f1_score: 0.8248\n",
            "Epoch 45/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3848 - acc: 0.8361 - precision: 0.8260 - recall: 0.8534 - f1_score: 0.8395 - val_loss: 0.4066 - val_acc: 0.8289 - val_precision: 0.8045 - val_recall: 0.8610 - val_f1_score: 0.8318\n",
            "Epoch 46/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3844 - acc: 0.8373 - precision: 0.8227 - recall: 0.8618 - f1_score: 0.8418 - val_loss: 0.4065 - val_acc: 0.8260 - val_precision: 0.8148 - val_recall: 0.8361 - val_f1_score: 0.8253\n",
            "Epoch 47/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3839 - acc: 0.8357 - precision: 0.8248 - recall: 0.8543 - f1_score: 0.8393 - val_loss: 0.4068 - val_acc: 0.8287 - val_precision: 0.8026 - val_recall: 0.8640 - val_f1_score: 0.8322\n",
            "Epoch 48/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3835 - acc: 0.8370 - precision: 0.8228 - recall: 0.8609 - f1_score: 0.8414 - val_loss: 0.4058 - val_acc: 0.8280 - val_precision: 0.8049 - val_recall: 0.8579 - val_f1_score: 0.8306\n",
            "Epoch 49/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3830 - acc: 0.8374 - precision: 0.8230 - recall: 0.8616 - f1_score: 0.8418 - val_loss: 0.4049 - val_acc: 0.8283 - val_precision: 0.8101 - val_recall: 0.8497 - val_f1_score: 0.8295\n",
            "Epoch 50/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3824 - acc: 0.8389 - precision: 0.8241 - recall: 0.8635 - f1_score: 0.8433 - val_loss: 0.4049 - val_acc: 0.8287 - val_precision: 0.8105 - val_recall: 0.8503 - val_f1_score: 0.8299\n",
            "Epoch 51/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3820 - acc: 0.8380 - precision: 0.8247 - recall: 0.8601 - f1_score: 0.8420 - val_loss: 0.4039 - val_acc: 0.8310 - val_precision: 0.8076 - val_recall: 0.8613 - val_f1_score: 0.8336\n",
            "Epoch 52/100\n",
            "26809/26809 [==============================] - 0s 17us/step - loss: 0.3815 - acc: 0.8389 - precision: 0.8231 - recall: 0.8653 - f1_score: 0.8436 - val_loss: 0.4033 - val_acc: 0.8292 - val_precision: 0.8135 - val_recall: 0.8464 - val_f1_score: 0.8296\n",
            "Epoch 53/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3811 - acc: 0.8395 - precision: 0.8250 - recall: 0.8635 - f1_score: 0.8438 - val_loss: 0.4030 - val_acc: 0.8310 - val_precision: 0.8100 - val_recall: 0.8570 - val_f1_score: 0.8329\n",
            "Epoch 54/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3804 - acc: 0.8392 - precision: 0.8248 - recall: 0.8632 - f1_score: 0.8435 - val_loss: 0.4030 - val_acc: 0.8317 - val_precision: 0.8080 - val_recall: 0.8638 - val_f1_score: 0.8350\n",
            "Epoch 55/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3803 - acc: 0.8395 - precision: 0.8243 - recall: 0.8645 - f1_score: 0.8439 - val_loss: 0.4026 - val_acc: 0.8316 - val_precision: 0.8059 - val_recall: 0.8658 - val_f1_score: 0.8348\n",
            "Epoch 56/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3797 - acc: 0.8407 - precision: 0.8240 - recall: 0.8681 - f1_score: 0.8455 - val_loss: 0.4018 - val_acc: 0.8323 - val_precision: 0.8161 - val_recall: 0.8503 - val_f1_score: 0.8329\n",
            "Epoch 57/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3793 - acc: 0.8401 - precision: 0.8257 - recall: 0.8640 - f1_score: 0.8444 - val_loss: 0.4013 - val_acc: 0.8325 - val_precision: 0.8129 - val_recall: 0.8561 - val_f1_score: 0.8339\n",
            "Epoch 58/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3790 - acc: 0.8409 - precision: 0.8255 - recall: 0.8664 - f1_score: 0.8455 - val_loss: 0.4011 - val_acc: 0.8325 - val_precision: 0.8081 - val_recall: 0.8643 - val_f1_score: 0.8353\n",
            "Epoch 59/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3784 - acc: 0.8411 - precision: 0.8246 - recall: 0.8684 - f1_score: 0.8459 - val_loss: 0.4008 - val_acc: 0.8332 - val_precision: 0.8179 - val_recall: 0.8497 - val_f1_score: 0.8335\n",
            "Epoch 60/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3782 - acc: 0.8414 - precision: 0.8264 - recall: 0.8661 - f1_score: 0.8458 - val_loss: 0.4005 - val_acc: 0.8329 - val_precision: 0.8102 - val_recall: 0.8619 - val_f1_score: 0.8352\n",
            "Epoch 61/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3777 - acc: 0.8416 - precision: 0.8259 - recall: 0.8675 - f1_score: 0.8462 - val_loss: 0.4005 - val_acc: 0.8328 - val_precision: 0.8058 - val_recall: 0.8692 - val_f1_score: 0.8363\n",
            "Epoch 62/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3772 - acc: 0.8420 - precision: 0.8253 - recall: 0.8695 - f1_score: 0.8468 - val_loss: 0.4001 - val_acc: 0.8341 - val_precision: 0.8151 - val_recall: 0.8567 - val_f1_score: 0.8354\n",
            "Epoch 63/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3770 - acc: 0.8424 - precision: 0.8260 - recall: 0.8691 - f1_score: 0.8470 - val_loss: 0.3992 - val_acc: 0.8329 - val_precision: 0.8149 - val_recall: 0.8540 - val_f1_score: 0.8340\n",
            "Epoch 64/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3766 - acc: 0.8425 - precision: 0.8264 - recall: 0.8689 - f1_score: 0.8471 - val_loss: 0.3988 - val_acc: 0.8329 - val_precision: 0.8097 - val_recall: 0.8628 - val_f1_score: 0.8354\n",
            "Epoch 65/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3763 - acc: 0.8430 - precision: 0.8264 - recall: 0.8701 - f1_score: 0.8477 - val_loss: 0.3988 - val_acc: 0.8351 - val_precision: 0.8098 - val_recall: 0.8685 - val_f1_score: 0.8381\n",
            "Epoch 66/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3759 - acc: 0.8442 - precision: 0.8259 - recall: 0.8739 - f1_score: 0.8492 - val_loss: 0.3985 - val_acc: 0.8347 - val_precision: 0.8185 - val_recall: 0.8528 - val_f1_score: 0.8353\n",
            "Epoch 67/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3756 - acc: 0.8426 - precision: 0.8269 - recall: 0.8684 - f1_score: 0.8471 - val_loss: 0.3980 - val_acc: 0.8350 - val_precision: 0.8155 - val_recall: 0.8585 - val_f1_score: 0.8364\n",
            "Epoch 68/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3754 - acc: 0.8439 - precision: 0.8272 - recall: 0.8712 - f1_score: 0.8486 - val_loss: 0.3971 - val_acc: 0.8346 - val_precision: 0.8126 - val_recall: 0.8622 - val_f1_score: 0.8366\n",
            "Epoch 69/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3750 - acc: 0.8445 - precision: 0.8278 - recall: 0.8716 - f1_score: 0.8491 - val_loss: 0.3970 - val_acc: 0.8354 - val_precision: 0.8106 - val_recall: 0.8679 - val_f1_score: 0.8383\n",
            "Epoch 70/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3745 - acc: 0.8455 - precision: 0.8283 - recall: 0.8734 - f1_score: 0.8502 - val_loss: 0.3970 - val_acc: 0.8353 - val_precision: 0.8113 - val_recall: 0.8664 - val_f1_score: 0.8379\n",
            "Epoch 71/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3744 - acc: 0.8445 - precision: 0.8266 - recall: 0.8736 - f1_score: 0.8495 - val_loss: 0.3965 - val_acc: 0.8347 - val_precision: 0.8091 - val_recall: 0.8685 - val_f1_score: 0.8378\n",
            "Epoch 72/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3740 - acc: 0.8452 - precision: 0.8270 - recall: 0.8747 - f1_score: 0.8502 - val_loss: 0.3963 - val_acc: 0.8353 - val_precision: 0.8123 - val_recall: 0.8646 - val_f1_score: 0.8376\n",
            "Epoch 73/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3737 - acc: 0.8446 - precision: 0.8280 - recall: 0.8716 - f1_score: 0.8492 - val_loss: 0.3959 - val_acc: 0.8346 - val_precision: 0.8094 - val_recall: 0.8676 - val_f1_score: 0.8375\n",
            "Epoch 74/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3733 - acc: 0.8453 - precision: 0.8281 - recall: 0.8731 - f1_score: 0.8500 - val_loss: 0.3957 - val_acc: 0.8356 - val_precision: 0.8103 - val_recall: 0.8689 - val_f1_score: 0.8386\n",
            "Epoch 75/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3731 - acc: 0.8458 - precision: 0.8281 - recall: 0.8744 - f1_score: 0.8506 - val_loss: 0.3953 - val_acc: 0.8359 - val_precision: 0.8145 - val_recall: 0.8625 - val_f1_score: 0.8378\n",
            "Epoch 76/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3729 - acc: 0.8453 - precision: 0.8276 - recall: 0.8739 - f1_score: 0.8501 - val_loss: 0.3957 - val_acc: 0.8363 - val_precision: 0.8097 - val_recall: 0.8719 - val_f1_score: 0.8396\n",
            "Epoch 77/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3726 - acc: 0.8449 - precision: 0.8272 - recall: 0.8735 - f1_score: 0.8497 - val_loss: 0.3949 - val_acc: 0.8357 - val_precision: 0.8114 - val_recall: 0.8673 - val_f1_score: 0.8384\n",
            "Epoch 78/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3721 - acc: 0.8463 - precision: 0.8278 - recall: 0.8762 - f1_score: 0.8513 - val_loss: 0.3946 - val_acc: 0.8368 - val_precision: 0.8163 - val_recall: 0.8619 - val_f1_score: 0.8385\n",
            "Epoch 79/100\n",
            "26809/26809 [==============================] - 0s 17us/step - loss: 0.3720 - acc: 0.8458 - precision: 0.8284 - recall: 0.8738 - f1_score: 0.8505 - val_loss: 0.3950 - val_acc: 0.8360 - val_precision: 0.8094 - val_recall: 0.8716 - val_f1_score: 0.8394\n",
            "Epoch 80/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3717 - acc: 0.8457 - precision: 0.8286 - recall: 0.8734 - f1_score: 0.8504 - val_loss: 0.3949 - val_acc: 0.8351 - val_precision: 0.8055 - val_recall: 0.8761 - val_f1_score: 0.8393\n",
            "Epoch 81/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3713 - acc: 0.8466 - precision: 0.8274 - recall: 0.8776 - f1_score: 0.8517 - val_loss: 0.3937 - val_acc: 0.8368 - val_precision: 0.8165 - val_recall: 0.8616 - val_f1_score: 0.8384\n",
            "Epoch 82/100\n",
            "26809/26809 [==============================] - 0s 17us/step - loss: 0.3711 - acc: 0.8466 - precision: 0.8283 - recall: 0.8762 - f1_score: 0.8516 - val_loss: 0.3937 - val_acc: 0.8369 - val_precision: 0.8138 - val_recall: 0.8664 - val_f1_score: 0.8393\n",
            "Epoch 83/100\n",
            "26809/26809 [==============================] - 0s 17us/step - loss: 0.3707 - acc: 0.8463 - precision: 0.8285 - recall: 0.8751 - f1_score: 0.8512 - val_loss: 0.3933 - val_acc: 0.8363 - val_precision: 0.8123 - val_recall: 0.8673 - val_f1_score: 0.8389\n",
            "Epoch 84/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3706 - acc: 0.8457 - precision: 0.8274 - recall: 0.8752 - f1_score: 0.8507 - val_loss: 0.3929 - val_acc: 0.8360 - val_precision: 0.8101 - val_recall: 0.8704 - val_f1_score: 0.8392\n",
            "Epoch 85/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3703 - acc: 0.8466 - precision: 0.8288 - recall: 0.8754 - f1_score: 0.8514 - val_loss: 0.3936 - val_acc: 0.8368 - val_precision: 0.8111 - val_recall: 0.8707 - val_f1_score: 0.8398\n",
            "Epoch 86/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3700 - acc: 0.8464 - precision: 0.8281 - recall: 0.8760 - f1_score: 0.8514 - val_loss: 0.3930 - val_acc: 0.8368 - val_precision: 0.8134 - val_recall: 0.8667 - val_f1_score: 0.8392\n",
            "Epoch 87/100\n",
            "26809/26809 [==============================] - 0s 17us/step - loss: 0.3698 - acc: 0.8466 - precision: 0.8282 - recall: 0.8762 - f1_score: 0.8515 - val_loss: 0.3924 - val_acc: 0.8374 - val_precision: 0.8159 - val_recall: 0.8640 - val_f1_score: 0.8393\n",
            "Epoch 88/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3694 - acc: 0.8470 - precision: 0.8300 - recall: 0.8742 - f1_score: 0.8516 - val_loss: 0.3925 - val_acc: 0.8368 - val_precision: 0.8086 - val_recall: 0.8749 - val_f1_score: 0.8405\n",
            "Epoch 89/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3693 - acc: 0.8474 - precision: 0.8286 - recall: 0.8777 - f1_score: 0.8524 - val_loss: 0.3924 - val_acc: 0.8366 - val_precision: 0.8070 - val_recall: 0.8774 - val_f1_score: 0.8407\n",
            "Epoch 90/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3689 - acc: 0.8472 - precision: 0.8282 - recall: 0.8778 - f1_score: 0.8523 - val_loss: 0.3913 - val_acc: 0.8381 - val_precision: 0.8171 - val_recall: 0.8640 - val_f1_score: 0.8399\n",
            "Epoch 91/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3688 - acc: 0.8467 - precision: 0.8290 - recall: 0.8753 - f1_score: 0.8515 - val_loss: 0.3916 - val_acc: 0.8371 - val_precision: 0.8110 - val_recall: 0.8716 - val_f1_score: 0.8402\n",
            "Epoch 92/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3686 - acc: 0.8474 - precision: 0.8286 - recall: 0.8777 - f1_score: 0.8524 - val_loss: 0.3907 - val_acc: 0.8392 - val_precision: 0.8189 - val_recall: 0.8637 - val_f1_score: 0.8407\n",
            "Epoch 93/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3683 - acc: 0.8478 - precision: 0.8291 - recall: 0.8777 - f1_score: 0.8527 - val_loss: 0.3908 - val_acc: 0.8375 - val_precision: 0.8107 - val_recall: 0.8734 - val_f1_score: 0.8409\n",
            "Epoch 94/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3680 - acc: 0.8474 - precision: 0.8289 - recall: 0.8772 - f1_score: 0.8524 - val_loss: 0.3915 - val_acc: 0.8395 - val_precision: 0.8147 - val_recall: 0.8716 - val_f1_score: 0.8422\n",
            "Epoch 95/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3677 - acc: 0.8479 - precision: 0.8292 - recall: 0.8779 - f1_score: 0.8529 - val_loss: 0.3906 - val_acc: 0.8384 - val_precision: 0.8156 - val_recall: 0.8673 - val_f1_score: 0.8407\n",
            "Epoch 96/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3675 - acc: 0.8478 - precision: 0.8299 - recall: 0.8767 - f1_score: 0.8527 - val_loss: 0.3911 - val_acc: 0.8384 - val_precision: 0.8117 - val_recall: 0.8740 - val_f1_score: 0.8417\n",
            "Epoch 97/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3673 - acc: 0.8483 - precision: 0.8298 - recall: 0.8778 - f1_score: 0.8532 - val_loss: 0.3918 - val_acc: 0.8363 - val_precision: 0.8037 - val_recall: 0.8825 - val_f1_score: 0.8413\n",
            "Epoch 98/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3671 - acc: 0.8478 - precision: 0.8290 - recall: 0.8780 - f1_score: 0.8528 - val_loss: 0.3895 - val_acc: 0.8377 - val_precision: 0.8100 - val_recall: 0.8749 - val_f1_score: 0.8412\n",
            "Epoch 99/100\n",
            "26809/26809 [==============================] - 0s 16us/step - loss: 0.3669 - acc: 0.8483 - precision: 0.8296 - recall: 0.8782 - f1_score: 0.8532 - val_loss: 0.3891 - val_acc: 0.8377 - val_precision: 0.8112 - val_recall: 0.8728 - val_f1_score: 0.8409\n",
            "Epoch 100/100\n",
            "26809/26809 [==============================] - 0s 15us/step - loss: 0.3666 - acc: 0.8478 - precision: 0.8290 - recall: 0.8780 - f1_score: 0.8528 - val_loss: 0.3889 - val_acc: 0.8393 - val_precision: 0.8138 - val_recall: 0.8728 - val_f1_score: 0.8422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xpGzBlnxyA4",
        "colab_type": "code",
        "outputId": "51622c48-2860-49c3-aaae-104e3cdb58ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot model loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOZKSEfD_5K",
        "colab_type": "code",
        "outputId": "164e2edb-a2d4-4f53-f933-35850afa863e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot model acuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTLssWBhjjGmXBQtjjDHtsmBhjDGmXf8fqIJyK14MaLQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CIT6vRWk5Ls",
        "colab_type": "code",
        "outputId": "3670faf5-8f6a-4049-b530-70dbfa04b39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "results = model.evaluate(X_val, Y_val)\n",
        "\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5395/5395 [==============================] - 0s 26us/step\n",
            "test loss, test acc: [0.48881267818507496, 0.7933271547176973, 0.8647264260567002, 0.8742937852901532, 0.8694837378776843]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLHgr2-flkuV",
        "colab_type": "code",
        "outputId": "4e6c4391-be46-4000-c86f-e38a98be778c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Y_val_true = [ enc[int(max(enc))] for enc in Y_val]\n",
        "\n",
        "print( 'Classification report\\n', classification_report(Y_val_true, model.predict_classes(X_val)) )"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.87      0.87      4248\n",
            "         1.0       0.51      0.49      0.50      1147\n",
            "\n",
            "    accuracy                           0.79      5395\n",
            "   macro avg       0.69      0.68      0.69      5395\n",
            "weighted avg       0.79      0.79      0.79      5395\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyrMuDtYBVNO",
        "colab_type": "code",
        "outputId": "c5458ac2-d442-4661-cb5c-e29cbd75c5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict on test\n",
        "\n",
        "Y_test_pred = model.predict_classes(X_test)\n",
        "print(Y_test_pred)\n",
        "\n",
        "with open(\"test_pred.txt\", \"w\") as txt_file:\n",
        "    for line in Y_test_pred:\n",
        "        txt_file.write(str(line) + \"\\n\") # works with any number of elements in"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}