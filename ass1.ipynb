{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzi27/adv-ml-assignment1/blob/master/ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABVe6x05udwR",
        "colab_type": "text"
      },
      "source": [
        "# Amrani Hamza - 807386\n",
        "\n",
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsPy5ahXujZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "78739932-62b0-4ea1-f3b4-c1bf82a5a397"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_data(path, train=True):\n",
        "    \"\"\"Load data from a CSV File\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    path: str\n",
        "        The path to the CSV file\n",
        "        \n",
        "    train: bool (default True)\n",
        "        Decide whether or not data are *training data*.\n",
        "        If True, some random shuffling is applied.\n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    X: numpy.ndarray \n",
        "        The data as a multi dimensional array of floats\n",
        "    ids: numpy.ndarray\n",
        "        A vector of ids for each sample\n",
        "    \"\"\"\n",
        "    text = pd.read_csv(path, encoding = \"ISO-8859-2\")\n",
        "    df = pd.read_csv(path)\n",
        "    X = df.values.copy()\n",
        "    if train:\n",
        "        np.random.shuffle(X)  \n",
        "        X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
        "        return X, labels\n",
        "    else:\n",
        "        X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
        "        return X, ids\n",
        "\n",
        "url_train = 'https://raw.githubusercontent.com/hamzi27/adv-ml-assignment1/master/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/hamzi27/adv-ml-assignment1/master/test.csv'\n",
        "\n",
        "X_train, Y_train = load_data(url_train, train=True)\n",
        "X_test, Y_test = load_data(url_test, train=False)\n",
        "\n",
        "print(\"Training set data\")\n",
        "print(X_train)\n",
        "\n",
        "print(\"Training set labels\")\n",
        "print(Y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set data\n",
            "[[2.0000e+00 1.0000e+00 1.0000e+00 ... 1.0000e+03 5.2000e+02 3.2500e+02]\n",
            " [2.0000e+00 2.0000e+00 1.0000e+00 ... 1.6000e+03 1.6000e+03 2.0000e+03]\n",
            " [1.0000e+00 1.0000e+00 1.0000e+00 ... 1.1720e+03 2.2460e+03 1.1720e+03]\n",
            " ...\n",
            " [2.0000e+00 2.0000e+00 1.0000e+00 ... 7.0100e+03 7.0130e+03 7.0150e+03]\n",
            " [1.0000e+00 2.0000e+00 2.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
            " [1.0000e+00 1.0000e+00 2.0000e+00 ... 4.0700e+03 2.5900e+02 1.1675e+04]]\n",
            "Training set labels\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRgLhpASlgK",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB7BcrYNSpgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9356ce5f-c72f-467a-d953-7ecfe58e849f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    \"\"\"Encode labels with values among 0 and `n-classes-1`\"\"\"\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = np_utils.to_categorical(y)\n",
        "    return y, encoder\n",
        "  \n",
        "  \n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "Y_train, encoder = preprocess_labels(Y_train)\n",
        "\n",
        "\n",
        "nb_classes = Y_train.shape[1]\n",
        "print(nb_classes, 'classes')\n",
        "\n",
        "dims = X_train.shape[1]\n",
        "print(dims, 'dims')\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 classes\n",
            "22 dims\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOsKfsy4Ta5C",
        "colab_type": "text"
      },
      "source": [
        "# Using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3OAAJsOTeyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04b8c580-ed6b-4e8d-a607-a6135757ec74"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers.core import Activation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(100, input_shape=(dims,)))\n",
        "model.add(Dense(80))\n",
        "model.add(Dense(50))\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train, validation_split=0.2, epochs=20, batch_size=32, verbose=True)\n",
        "model.evaluate(X_test, Y_test)\n",
        "\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 100)               2300      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 80)                8080      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 50)                4050      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 102       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 14,532\n",
            "Trainable params: 14,532\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 21600 samples, validate on 5400 samples\n",
            "Epoch 1/10\n",
            "21600/21600 [==============================] - 1s 61us/step - loss: 0.4836 - acc: 0.8002 - val_loss: 0.4567 - val_acc: 0.8220\n",
            "Epoch 2/10\n",
            "21600/21600 [==============================] - 1s 47us/step - loss: 0.4738 - acc: 0.8062 - val_loss: 0.4576 - val_acc: 0.8143\n",
            "Epoch 3/10\n",
            "21600/21600 [==============================] - 1s 46us/step - loss: 0.4734 - acc: 0.8064 - val_loss: 0.4588 - val_acc: 0.8126\n",
            "Epoch 4/10\n",
            "21600/21600 [==============================] - 1s 45us/step - loss: 0.4731 - acc: 0.8055 - val_loss: 0.4565 - val_acc: 0.8150\n",
            "Epoch 5/10\n",
            "21600/21600 [==============================] - 1s 47us/step - loss: 0.4727 - acc: 0.8051 - val_loss: 0.4578 - val_acc: 0.8154\n",
            "Epoch 6/10\n",
            "21600/21600 [==============================] - 1s 46us/step - loss: 0.4722 - acc: 0.8051 - val_loss: 0.4579 - val_acc: 0.8187\n",
            "Epoch 7/10\n",
            "21600/21600 [==============================] - 1s 46us/step - loss: 0.4720 - acc: 0.8066 - val_loss: 0.4579 - val_acc: 0.8191\n",
            "Epoch 8/10\n",
            "21600/21600 [==============================] - 1s 45us/step - loss: 0.4716 - acc: 0.8081 - val_loss: 0.4588 - val_acc: 0.8204\n",
            "Epoch 9/10\n",
            "21600/21600 [==============================] - 1s 44us/step - loss: 0.4711 - acc: 0.8077 - val_loss: 0.4584 - val_acc: 0.8117\n",
            "Epoch 10/10\n",
            "21600/21600 [==============================] - 1s 46us/step - loss: 0.4715 - acc: 0.8054 - val_loss: 0.4584 - val_acc: 0.8169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-5750f0c2fd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_6 to have shape (2,) but got array with shape (1,)"
          ]
        }
      ]
    }
  ]
}